{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKing-283/37_Sustainability/blob/main/Hackwave.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZmBLWymzm09"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "uF5Hqrs8z42V",
        "outputId": "2d66971b-7e2e-4d6b-9e3e-d6e9af832688"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 43823,\n  \"fields\": [\n    {\n      \"column\": \"DateTime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2019-01-01 01:00:00\",\n        \"max\": \"2023-12-31 23:00:00\",\n        \"num_unique_values\": 43823,\n        \"samples\": [\n          \"2021-06-21 09:00:00\",\n          \"2019-03-07 11:00:00\",\n          \"2023-11-24 18:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pressure | (atm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005427771085839196,\n        \"min\": 0.958598,\n        \"max\": 1.00558,\n        \"num_unique_values\": 17987,\n        \"samples\": [\n          0.980719,\n          0.980419,\n          0.987696\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Wind speed | (m/s)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.0121272081252877,\n        \"min\": 0.14,\n        \"max\": 19.725,\n        \"num_unique_values\": 11765,\n        \"samples\": [\n          6.887,\n          1.558,\n          8.767\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Air temperature | (\\u00b0C)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.009168291453559,\n        \"min\": -14.066,\n        \"max\": 38.805,\n        \"num_unique_values\": 25816,\n        \"samples\": [\n          25.267,\n          10.793,\n          20.928\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Power generated by system | (MW)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.234998035851596,\n        \"min\": 0.0,\n        \"max\": 61.245400000000004,\n        \"num_unique_values\": 31895,\n        \"samples\": [\n          18.8085,\n          32.2592,\n          18.018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-44903a27-04bc-451f-bce6-abad5fa2abf2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DateTime</th>\n",
              "      <th>Pressure | (atm)</th>\n",
              "      <th>Wind speed | (m/s)</th>\n",
              "      <th>Air temperature | (°C)</th>\n",
              "      <th>Power generated by system | (MW)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-01 01:00:00.000</td>\n",
              "      <td>0.979103</td>\n",
              "      <td>9.014</td>\n",
              "      <td>10.926</td>\n",
              "      <td>33.6881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-01-01 02:00:00.000</td>\n",
              "      <td>0.979566</td>\n",
              "      <td>9.428</td>\n",
              "      <td>9.919</td>\n",
              "      <td>37.2619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-01-01 03:00:00.005</td>\n",
              "      <td>0.979937</td>\n",
              "      <td>8.700</td>\n",
              "      <td>8.567</td>\n",
              "      <td>30.5029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-01-01 04:00:00.010</td>\n",
              "      <td>0.980053</td>\n",
              "      <td>8.481</td>\n",
              "      <td>7.877</td>\n",
              "      <td>28.4192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-01 05:00:00.015</td>\n",
              "      <td>0.979867</td>\n",
              "      <td>8.383</td>\n",
              "      <td>7.259</td>\n",
              "      <td>27.3703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43818</th>\n",
              "      <td>2023-12-31 19:00:00.000</td>\n",
              "      <td>0.985015</td>\n",
              "      <td>8.703</td>\n",
              "      <td>11.713</td>\n",
              "      <td>30.4221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43819</th>\n",
              "      <td>2023-12-31 20:00:00.000</td>\n",
              "      <td>0.985244</td>\n",
              "      <td>8.854</td>\n",
              "      <td>12.115</td>\n",
              "      <td>32.0366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43820</th>\n",
              "      <td>2023-12-31 21:00:00.000</td>\n",
              "      <td>0.985639</td>\n",
              "      <td>9.333</td>\n",
              "      <td>11.856</td>\n",
              "      <td>36.3990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43821</th>\n",
              "      <td>2023-12-31 22:00:00.000</td>\n",
              "      <td>0.986212</td>\n",
              "      <td>9.457</td>\n",
              "      <td>10.761</td>\n",
              "      <td>37.7404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43822</th>\n",
              "      <td>2023-12-31 23:00:00.000</td>\n",
              "      <td>0.987183</td>\n",
              "      <td>9.324</td>\n",
              "      <td>8.380</td>\n",
              "      <td>36.7908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43823 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44903a27-04bc-451f-bce6-abad5fa2abf2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44903a27-04bc-451f-bce6-abad5fa2abf2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44903a27-04bc-451f-bce6-abad5fa2abf2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-005033f4-710e-41b3-9ea4-1a860efe7ab6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-005033f4-710e-41b3-9ea4-1a860efe7ab6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-005033f4-710e-41b3-9ea4-1a860efe7ab6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bc27efb6-53db-4e78-a8ed-a8739ee724c5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bc27efb6-53db-4e78-a8ed-a8739ee724c5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                     DateTime  Pressure | (atm)  Wind speed | (m/s)  \\\n",
              "0     2019-01-01 01:00:00.000          0.979103               9.014   \n",
              "1     2019-01-01 02:00:00.000          0.979566               9.428   \n",
              "2     2019-01-01 03:00:00.005          0.979937               8.700   \n",
              "3     2019-01-01 04:00:00.010          0.980053               8.481   \n",
              "4     2019-01-01 05:00:00.015          0.979867               8.383   \n",
              "...                       ...               ...                 ...   \n",
              "43818 2023-12-31 19:00:00.000          0.985015               8.703   \n",
              "43819 2023-12-31 20:00:00.000          0.985244               8.854   \n",
              "43820 2023-12-31 21:00:00.000          0.985639               9.333   \n",
              "43821 2023-12-31 22:00:00.000          0.986212               9.457   \n",
              "43822 2023-12-31 23:00:00.000          0.987183               9.324   \n",
              "\n",
              "       Air temperature | (°C)  Power generated by system | (MW)  \n",
              "0                      10.926                           33.6881  \n",
              "1                       9.919                           37.2619  \n",
              "2                       8.567                           30.5029  \n",
              "3                       7.877                           28.4192  \n",
              "4                       7.259                           27.3703  \n",
              "...                       ...                               ...  \n",
              "43818                  11.713                           30.4221  \n",
              "43819                  12.115                           32.0366  \n",
              "43820                  11.856                           36.3990  \n",
              "43821                  10.761                           37.7404  \n",
              "43822                   8.380                           36.7908  \n",
              "\n",
              "[43823 rows x 5 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df= pd.read_excel('/content/all_wind_power_data.xlsx')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNtRnxZs3pLM",
        "outputId": "ab7d8d61-0dfb-4447-9488-3f6774a68d8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns\n",
        "'Pressure | (atm)' in df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr14Igus4ssE",
        "outputId": "2d079bd4-7760-4977-b52a-d2f578c0b8f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        0.979103\n",
              "1        0.979566\n",
              "2        0.979937\n",
              "3        0.980053\n",
              "4        0.979867\n",
              "           ...   \n",
              "43818    0.985015\n",
              "43819    0.985244\n",
              "43820    0.985639\n",
              "43821    0.986212\n",
              "43822    0.987183\n",
              "Name: Pressure | (atm), Length: 43823, dtype: float64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = df['Pressure | (atm)']\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdxsldwe5J1k",
        "outputId": "f48ecbf7-f6b6-4177-baf7-2469bdfde2f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       2019-01-01 01:00:00.000\n",
              "1       2019-01-01 02:00:00.000\n",
              "2       2019-01-01 03:00:00.005\n",
              "3       2019-01-01 04:00:00.010\n",
              "4       2019-01-01 05:00:00.015\n",
              "                  ...          \n",
              "43818   2023-12-31 19:00:00.000\n",
              "43819   2023-12-31 20:00:00.000\n",
              "43820   2023-12-31 21:00:00.000\n",
              "43821   2023-12-31 22:00:00.000\n",
              "43822   2023-12-31 23:00:00.000\n",
              "Name: DateTime, Length: 43823, dtype: datetime64[ns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X=df['DateTime']\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1TNS9sx7B1K"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkE1f7Oi7YWZ",
        "outputId": "53661467-7ef6-43d9-d01d-79916ddfe601"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "36708   2023-03-10 13:00:00.000\n",
              "14327   2020-08-20 00:00:00.000\n",
              "18119   2021-01-25 00:00:00.000\n",
              "15430   2020-10-04 23:00:00.000\n",
              "23970   2021-09-25 19:00:00.000\n",
              "                  ...          \n",
              "16304   2020-11-10 09:00:00.000\n",
              "79      2019-01-04 08:00:00.390\n",
              "12119   2020-05-20 00:00:00.000\n",
              "14147   2020-08-12 12:00:00.000\n",
              "38408   2023-05-20 09:00:00.000\n",
              "Name: DateTime, Length: 35058, dtype: datetime64[ns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vjo8By974Lg",
        "outputId": "eb583c96-b9c1-4a8b-e233-5284658477cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39811   2023-07-17 20:00:00\n",
              "29742   2022-05-24 07:00:00\n",
              "24121   2021-10-02 02:00:00\n",
              "20281   2021-04-25 02:00:00\n",
              "5334    2019-08-11 07:00:00\n",
              "                ...        \n",
              "17025   2020-12-10 10:00:00\n",
              "41308   2023-09-18 05:00:00\n",
              "3550    2019-05-28 23:00:00\n",
              "9311    2020-01-24 00:00:00\n",
              "5694    2019-08-26 07:00:00\n",
              "Name: DateTime, Length: 8765, dtype: datetime64[ns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHv-s1KG78eO"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOoY5ia2-ga_"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsK_OOE9__AD"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(X_train).reshape(-1, 1)\n",
        "y_train = np.array(y_train).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "j3i22927AXsd",
        "outputId": "4bedd6d6-eb3a-4b94-da30-fa21b41a85b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "TiroMzTsAcSQ",
        "outputId": "546259f4-4cb5-4488-bf35-2e2f69178298"
      },
      "outputs": [
        {
          "ename": "UFuncTypeError",
          "evalue": "ufunc 'matmul' did not contain a loop with signature matching types (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>) -> None",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;31mDTypePromotionError\u001b[0m: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1a222422c78a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_intercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     if (\n",
            "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'matmul' did not contain a loop with signature matching types (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>) -> None"
          ]
        }
      ],
      "source": [
        "y_train_pred = lr.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dALDfkjQvd-",
        "outputId": "108178e8-086c-4b04-f6ea-3a6a5466da20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([26.70133287, 27.83985378, 30.70968487, 32.89997017, 33.91305551,\n",
              "        9.60080843,  8.15982581, 28.92324649, 18.5653589 ,  5.32271318])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the data\n",
        "data = {\n",
        "    'DateTime': ['2019-01-01 01:00:00', '2019-01-01 02:00:00', '2019-01-01 03:00:00', '2019-01-01 04:00:00', '2019-01-01 05:00:00', '2019-01-01 06:00:00', '2019-01-01 07:00:00', '2019-01-01 08:00:00', '2019-01-01 09:00:00', '2019-01-01 10:00:00', '2019-01-01 11:00:00', '2019-01-01 12:00:00', '2019-01-01 13:00:00'],\n",
        "    'Pressure': [0.979103, 0.979566, 0.979937, 0.980053, 0.979867, 0.979884, 0.980318, 0.980597, 0.980711, 0.980902, 0.981166, 0.981347, 0.981703],\n",
        "    'Wind_speed': [9.014, 9.428, 8.7, 8.481, 8.383, 8.256, 6.476, 5.906, 5.557, 6.081, 7.384, 9.072, 7.142],\n",
        "    'Air_temperature': [10.926, 9.919, 8.567, 7.877, 7.259, 6.57, 5.897, 5.109, 4.413, 3.754, 3.169, 2.637, 1.948],\n",
        "    'Power_generated': [33.6881, 37.2619, 30.5029, 28.4192, 27.3703, 25.8059, 11.5468, 8.36076, 6.42664, 9.34945, 18.6136, 35.3811, 17.3315]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert 'DateTime' column to datetime format\n",
        "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df[['Pressure', 'Wind_speed', 'Air_temperature']]\n",
        "y = df['Power_generated']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
        "\n",
        "# Choose a model (Linear Regression)\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred\n",
        "y_train_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C01mMmc5h5XB",
        "outputId": "f139e64c-74ee-4231-aadc-cc6eca137056"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model accuracy: 0.25464917284654875\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Read data from the Excel file\n",
        "data = pd.read_excel(\"/content/all_wind_power_data.xlsx\")\n",
        "\n",
        "# Drop the datetime column\n",
        "data = data.drop(columns=['DateTime'])\n",
        "\n",
        "# Assume the last column contains the target labels\n",
        "X = data.iloc[:, :-1]  # Features\n",
        "y = data.iloc[:, -1]   # Target labels\n",
        "\n",
        "# Encode categorical labels if needed\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the model\n",
        "model = SGDClassifier(loss='log', random_state=42)\n",
        "\n",
        "# Train the initial model\n",
        "model.partial_fit(X_train, y_train, classes=np.unique(y))\n",
        "\n",
        "# Now, as new data arrives, you can update the model incrementally using `partial_fit`:\n",
        "# new_data = pd.read_csv(\"new_data.csv\")\n",
        "# X_new = new_data.iloc[:, :-1]\n",
        "# y_new = label_encoder.transform(new_data.iloc[:, -1])\n",
        "# model.partial_fit(X_new, y_new)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = model.score(X_test, y_test)\n",
        "print(\"Model accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MCMLjgtesO-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read data from the Excel file\n",
        "data = pd.read_excel(\"/content/all_wind_power_data.xlsx\")\n",
        "\n",
        "# Drop the datetime column\n",
        "data = data.drop(columns=['DateTime'])\n",
        "\n",
        "# Assume the last column contains the target labels\n",
        "X = data.iloc[:, :-1].values  # Features\n",
        "y = data.iloc[:, -1].values   # Target labels\n",
        "\n",
        "# Encode categorical labels if needed\n",
        "# Assuming y is already encoded\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dropout(0.5),  # Dropout layer to reduce overfitting\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=20, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBNW7gZIjPCC",
        "outputId": "c40d74ad-54b2-4812-ab8f-4c2318ddcd80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "439/439 [==============================] - 4s 5ms/step - loss: -549495.1875 - accuracy: 2.4959e-04 - val_loss: -3075922.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "439/439 [==============================] - 2s 6ms/step - loss: -20746576.0000 - accuracy: 0.0479 - val_loss: -55201268.0000 - val_accuracy: 0.0878\n",
            "Epoch 3/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -138286736.0000 - accuracy: 0.0725 - val_loss: -261074784.0000 - val_accuracy: 0.1306\n",
            "Epoch 4/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -466990784.0000 - accuracy: 0.0791 - val_loss: -743579136.0000 - val_accuracy: 0.1466\n",
            "Epoch 5/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -1132507776.0000 - accuracy: 0.0843 - val_loss: -1631133056.0000 - val_accuracy: 0.1593\n",
            "Epoch 6/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -2254857216.0000 - accuracy: 0.0851 - val_loss: -3044105728.0000 - val_accuracy: 0.1701\n",
            "Epoch 7/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -3948903936.0000 - accuracy: 0.0858 - val_loss: -5099672064.0000 - val_accuracy: 0.1750\n",
            "Epoch 8/20\n",
            "439/439 [==============================] - 3s 6ms/step - loss: -6339065856.0000 - accuracy: 0.0882 - val_loss: -7907773952.0000 - val_accuracy: 0.1781\n",
            "Epoch 9/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -9540398080.0000 - accuracy: 0.0856 - val_loss: -11598438400.0000 - val_accuracy: 0.1801\n",
            "Epoch 10/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -13635908608.0000 - accuracy: 0.0885 - val_loss: -16243061760.0000 - val_accuracy: 0.1821\n",
            "Epoch 11/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -18758916096.0000 - accuracy: 0.0869 - val_loss: -22015119360.0000 - val_accuracy: 0.1838\n",
            "Epoch 12/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -25077553152.0000 - accuracy: 0.0889 - val_loss: -29004328960.0000 - val_accuracy: 0.1848\n",
            "Epoch 13/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -32618827776.0000 - accuracy: 0.0904 - val_loss: -37341712384.0000 - val_accuracy: 0.1861\n",
            "Epoch 14/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -41509654528.0000 - accuracy: 0.0913 - val_loss: -47117897728.0000 - val_accuracy: 0.1867\n",
            "Epoch 15/20\n",
            "439/439 [==============================] - 3s 6ms/step - loss: -51852918784.0000 - accuracy: 0.0912 - val_loss: -58463887360.0000 - val_accuracy: 0.1868\n",
            "Epoch 16/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -63995273216.0000 - accuracy: 0.0882 - val_loss: -71558717440.0000 - val_accuracy: 0.1871\n",
            "Epoch 17/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -77813899264.0000 - accuracy: 0.0915 - val_loss: -86548119552.0000 - val_accuracy: 0.1874\n",
            "Epoch 18/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -93632970752.0000 - accuracy: 0.0899 - val_loss: -103527153664.0000 - val_accuracy: 0.1875\n",
            "Epoch 19/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -111327870976.0000 - accuracy: 0.0902 - val_loss: -122668687360.0000 - val_accuracy: 0.1875\n",
            "Epoch 20/20\n",
            "439/439 [==============================] - 2s 4ms/step - loss: -131039502336.0000 - accuracy: 0.0887 - val_loss: -144024584192.0000 - val_accuracy: 0.1880\n",
            "274/274 [==============================] - 1s 2ms/step - loss: -148908474368.0000 - accuracy: 0.1800\n",
            "Test Loss: -148908474368.0\n",
            "Test Accuracy: 0.18003422021865845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read data from the Excel file\n",
        "data = pd.read_excel(\"/content/all_wind_power_data.xlsx\")\n",
        "\n",
        "# Drop the datetime column\n",
        "data = data.drop(columns=['DateTime'])\n",
        "\n",
        "# Assume the last column contains the target labels\n",
        "X = data.iloc[:, :-1].values  # Features\n",
        "y = data.iloc[:, -1].values   # Target labels\n",
        "\n",
        "# Encode categorical labels if needed\n",
        "# Assuming y is already encoded\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.BatchNormalization(),  # Batch normalization layer\n",
        "    tf.keras.layers.Dropout(0.5),  # Dropout layer\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),  # Dropout layer\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Implement learning rate scheduling\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.01,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9\n",
        ")\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "# Compile the model with custom optimizer\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=30, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXQA8r3nlOfH",
        "outputId": "976680be-40ba-4351-84a4-651eec002a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "439/439 [==============================] - 6s 7ms/step - loss: -5053872128.0000 - accuracy: 0.0856 - val_loss: -28684318720.0000 - val_accuracy: 0.2657\n",
            "Epoch 2/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -187106295808.0000 - accuracy: 0.0790 - val_loss: -497831772160.0000 - val_accuracy: 0.2410\n",
            "Epoch 3/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -1207691902976.0000 - accuracy: 0.0625 - val_loss: -2317425836032.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -4034747432960.0000 - accuracy: 0.0000e+00 - val_loss: -6502948536320.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -9702072123392.0000 - accuracy: 0.0000e+00 - val_loss: -14063739338752.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "439/439 [==============================] - 2s 6ms/step - loss: -19195257421824.0000 - accuracy: 0.0000e+00 - val_loss: -26074406715392.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "439/439 [==============================] - 3s 7ms/step - loss: -33395539181568.0000 - accuracy: 0.0000e+00 - val_loss: -43843294593024.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -52961405304832.0000 - accuracy: 0.0000e+00 - val_loss: -66406217416704.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "439/439 [==============================] - 2s 6ms/step - loss: -78991419506688.0000 - accuracy: 0.0000e+00 - val_loss: -96412779937792.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -111849949364224.0000 - accuracy: 0.0000e+00 - val_loss: -133939318489088.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -151691131355136.0000 - accuracy: 0.0000e+00 - val_loss: -179112937259008.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "439/439 [==============================] - 3s 7ms/step - loss: -200267899338752.0000 - accuracy: 0.0000e+00 - val_loss: -232356824743936.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -258294954328064.0000 - accuracy: 0.0000e+00 - val_loss: -298405301583872.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -327070248861696.0000 - accuracy: 0.0000e+00 - val_loss: -377465281183744.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -405542556139520.0000 - accuracy: 0.0000e+00 - val_loss: -457204335378432.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -496109055115264.0000 - accuracy: 0.0000e+00 - val_loss: -564542849417216.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "439/439 [==============================] - 3s 6ms/step - loss: -598378132013056.0000 - accuracy: 0.0000e+00 - val_loss: -666427056979968.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "439/439 [==============================] - 3s 6ms/step - loss: -713792560300032.0000 - accuracy: 0.0000e+00 - val_loss: -804561124065280.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -843423800098816.0000 - accuracy: 0.0000e+00 - val_loss: -932802539290624.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -981637928058880.0000 - accuracy: 0.0000e+00 - val_loss: -1080689604689920.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -1141616131702784.0000 - accuracy: 0.0000e+00 - val_loss: -1241173070970880.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -1312311553818624.0000 - accuracy: 0.0000e+00 - val_loss: -1426695391281152.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "439/439 [==============================] - 3s 8ms/step - loss: -1498063654879232.0000 - accuracy: 0.0000e+00 - val_loss: -1639520818692096.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -1706027716182016.0000 - accuracy: 0.0000e+00 - val_loss: -1867489092829184.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -1926984053555200.0000 - accuracy: 0.0000e+00 - val_loss: -2090757062131712.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -2175243095375872.0000 - accuracy: 0.0000e+00 - val_loss: -2366833533386752.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -2434953593749504.0000 - accuracy: 0.0000e+00 - val_loss: -2620280358830080.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/30\n",
            "439/439 [==============================] - 3s 6ms/step - loss: -2712637456515072.0000 - accuracy: 0.0000e+00 - val_loss: -2955852864552960.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/30\n",
            "439/439 [==============================] - 3s 6ms/step - loss: -3011131241136128.0000 - accuracy: 0.0000e+00 - val_loss: -3255320533008384.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/30\n",
            "439/439 [==============================] - 2s 5ms/step - loss: -3338734435041280.0000 - accuracy: 0.0000e+00 - val_loss: -3610310585876480.0000 - val_accuracy: 0.0000e+00\n",
            "274/274 [==============================] - 1s 2ms/step - loss: -3751663596732416.0000 - accuracy: 0.0000e+00\n",
            "Test Loss: -3751663596732416.0\n",
            "Test Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7QNtqTcDBjFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read data from the Excel file\n",
        "data = pd.read_excel(\"/content/wind_power_gen_3months_validation_data.xlsx\")\n",
        "\n",
        "# Drop the DateTime column if not needed\n",
        "data = data.drop(columns=['DateTime'])\n",
        "\n",
        "# Define and fit the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data_scaled[:, :-3]  # Features: energy produced data\n",
        "y = data_scaled[:, -3:]  # Targets: grid stability, unit consumption, and price per unit\n",
        "\n",
        "# Reshape the input data for LSTM\n",
        "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    tf.keras.layers.Dense(3)  # Output layer for three targets\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Print the test loss\n",
        "print(\"Test Loss:\", test_loss)\n",
        "\n",
        "# Calculate accuracy for each target (you may use different metrics for each target)\n",
        "# Assuming accuracy means within a certain threshold for regression values\n",
        "threshold = 0.1  # Define a threshold for considering predictions as accurate\n",
        "accuracies = []\n",
        "for i in range(3):\n",
        "    accurate_predictions = np.abs(predictions[:, i] - y_test[:, i]) <= threshold\n",
        "    accuracy = np.mean(accurate_predictions)\n",
        "    accuracies.append(accuracy)\n",
        "    print(\"Accuracy for Target {}: {:.2f}%\".format(i+1, accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzmhCThs1wsr",
        "outputId": "5b1d2f17-26b0-4046-ecf6-5eeff375fffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "110/110 [==============================] - 2s 4ms/step - loss: 0.9719\n",
            "Epoch 2/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9410\n",
            "Epoch 3/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9387\n",
            "Epoch 4/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9377\n",
            "Epoch 5/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9369\n",
            "Epoch 6/50\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.9361\n",
            "Epoch 7/50\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.9358\n",
            "Epoch 8/50\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.9355\n",
            "Epoch 9/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9353\n",
            "Epoch 10/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9353\n",
            "Epoch 11/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9355\n",
            "Epoch 12/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9348\n",
            "Epoch 13/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9344\n",
            "Epoch 14/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9339\n",
            "Epoch 15/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9349\n",
            "Epoch 16/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9341\n",
            "Epoch 17/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9343\n",
            "Epoch 18/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9337\n",
            "Epoch 19/50\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.9346\n",
            "Epoch 20/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9343\n",
            "Epoch 21/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 22/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9345\n",
            "Epoch 23/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9341\n",
            "Epoch 24/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9341\n",
            "Epoch 25/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 26/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9341\n",
            "Epoch 27/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9345\n",
            "Epoch 28/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 29/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9343\n",
            "Epoch 30/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 31/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9340\n",
            "Epoch 32/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 33/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9343\n",
            "Epoch 34/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9343\n",
            "Epoch 35/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9346\n",
            "Epoch 36/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9343\n",
            "Epoch 37/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9343\n",
            "Epoch 38/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 39/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9341\n",
            "Epoch 40/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9349\n",
            "Epoch 41/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9341\n",
            "Epoch 42/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 43/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9341\n",
            "Epoch 44/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9343\n",
            "Epoch 45/50\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.9338\n",
            "Epoch 46/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9346\n",
            "Epoch 47/50\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.9343\n",
            "Epoch 48/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 49/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9337\n",
            "Epoch 50/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9347\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.9262\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Test Loss: 0.926228404045105\n",
            "Accuracy for Target 1: 7.32%\n",
            "Accuracy for Target 2: 6.64%\n",
            "Accuracy for Target 3: 6.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uZSkswSM5rzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read data from the Excel file\n",
        "data = pd.read_excel(\"/content/wind_power_gen_3months_validation_data.xlsx\")\n",
        "\n",
        "# Drop the DateTime column if not needed\n",
        "data = data.drop(columns=['DateTime'])\n",
        "\n",
        "# Define and fit the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data_scaled[:, :-3]  # Features: energy produced data\n",
        "y = data_scaled[:, -3:]  # Targets: grid stability, unit consumption, and price per unit\n",
        "\n",
        "# Reshape the input data for LSTM\n",
        "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    tf.keras.layers.Dense(3)  # Output layer for three targets\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Print the test loss\n",
        "print(\"Test Loss:\", test_loss)\n",
        "\n",
        "# Calculate accuracy for each target (you may use different metrics for each target)\n",
        "# Assuming accuracy means within a certain threshold for regression values\n",
        "threshold = 0.1  # Define a threshold for considering predictions as accurate\n",
        "accuracies = []\n",
        "for i in range(3):\n",
        "    accurate_predictions = np.abs(predictions[:, i] - y_test[:, i]) <= threshold\n",
        "    accuracy = np.mean(accurate_predictions)\n",
        "    accuracies.append(accuracy)\n",
        "    print(\"Accuracy for Target {}: {:.2f}%\".format(i+1, accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1d2f17-26b0-4046-ecf6-5eeff375fffb",
        "id": "mZRXWsg55r_S"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "110/110 [==============================] - 2s 4ms/step - loss: 0.9719\n",
            "Epoch 2/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9410\n",
            "Epoch 3/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9387\n",
            "Epoch 4/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9377\n",
            "Epoch 5/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9369\n",
            "Epoch 6/50\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.9361\n",
            "Epoch 7/50\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.9358\n",
            "Epoch 8/50\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.9355\n",
            "Epoch 9/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9353\n",
            "Epoch 10/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9353\n",
            "Epoch 11/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9355\n",
            "Epoch 12/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9348\n",
            "Epoch 13/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9344\n",
            "Epoch 14/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9339\n",
            "Epoch 15/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9349\n",
            "Epoch 16/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9341\n",
            "Epoch 17/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9343\n",
            "Epoch 18/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9337\n",
            "Epoch 19/50\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.9346\n",
            "Epoch 20/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9343\n",
            "Epoch 21/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 22/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9345\n",
            "Epoch 23/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9341\n",
            "Epoch 24/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9341\n",
            "Epoch 25/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 26/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9341\n",
            "Epoch 27/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9345\n",
            "Epoch 28/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 29/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9343\n",
            "Epoch 30/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 31/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9340\n",
            "Epoch 32/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 33/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9343\n",
            "Epoch 34/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9343\n",
            "Epoch 35/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9346\n",
            "Epoch 36/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9343\n",
            "Epoch 37/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9343\n",
            "Epoch 38/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 39/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9341\n",
            "Epoch 40/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9349\n",
            "Epoch 41/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9341\n",
            "Epoch 42/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 43/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9341\n",
            "Epoch 44/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9343\n",
            "Epoch 45/50\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.9338\n",
            "Epoch 46/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.9346\n",
            "Epoch 47/50\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.9343\n",
            "Epoch 48/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9342\n",
            "Epoch 49/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9337\n",
            "Epoch 50/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.9347\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.9262\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Test Loss: 0.926228404045105\n",
            "Accuracy for Target 1: 7.32%\n",
            "Accuracy for Target 2: 6.64%\n",
            "Accuracy for Target 3: 6.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ylVOBQH5k7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read data from the Excel file\n",
        "data = pd.read_excel(\"/content/all_wind_power_data.xlsx\")\n",
        "\n",
        "# Drop the DateTime column if not needed\n",
        "data = data.drop(columns=['DateTime'])\n",
        "\n",
        "# Define and fit the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data_scaled[:, :-3]  # Features: energy produced data\n",
        "y = data_scaled[:, -3:]  # Targets: grid stability, unit consumption, and price per unit\n",
        "\n",
        "# Reshape the input data for LSTM\n",
        "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    tf.keras.layers.Dense(3)  # Output layer for three targets\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Print the test loss\n",
        "print(\"Test Loss:\", test_loss)\n",
        "\n",
        "# Calculate accuracy for each target (you may use different metrics for each target)\n",
        "# Assuming accuracy means within a certain threshold for regression values\n",
        "threshold = 0.1  # Define a threshold for considering predictions as accurate\n",
        "accuracies = []\n",
        "for i in range(3):\n",
        "    accurate_predictions = np.abs(predictions[:, i] - y_test[:, i]) <= threshold\n",
        "    accuracy = np.mean(accurate_predictions)\n",
        "    accuracies.append(accuracy)\n",
        "    print(\"Accuracy for Target {}: {:.2f}%\".format(i+1, accuracy * 100))\n",
        "\n",
        "# Calculate the total power generated (p)\n",
        "total_power_generated = data['Total Power Generated'].sum()\n",
        "\n",
        "# Define the percentages for each node\n",
        "percentage_node1 = 0.20\n",
        "percentage_node2 = 0.45\n",
        "percentage_node3 = 0.35\n",
        "\n",
        "# Calculate the power allocated to each node\n",
        "power_node1 = total_power_generated * percentage_node1\n",
        "power_node2 = total_power_generated * percentage_node2\n",
        "power_node3 = total_power_generated * percentage_node3\n",
        "\n",
        "print(\"Power for Node 1:\", power_node1)\n",
        "print(\"Power for Node 2:\", power_node2)\n",
        "print(\"Power for Node 3:\", power_node3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78486bd6-2d51-42af-df62-e37ece02d7ce",
        "id": "GLqKW6TB5tkF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2192/2192 [==============================] - 11s 4ms/step - loss: 0.8831\n",
            "Epoch 2/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8675\n",
            "Epoch 3/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8649\n",
            "Epoch 4/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8639\n",
            "Epoch 5/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8633\n",
            "Epoch 6/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8631\n",
            "Epoch 7/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8626\n",
            "Epoch 8/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8629\n",
            "Epoch 9/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8626\n",
            "Epoch 10/50\n",
            "2192/2192 [==============================] - 11s 5ms/step - loss: 0.8628\n",
            "Epoch 11/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8626\n",
            "Epoch 12/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8627\n",
            "Epoch 13/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8626\n",
            "Epoch 14/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8624\n",
            "Epoch 15/50\n",
            "2192/2192 [==============================] - 12s 5ms/step - loss: 0.8625\n",
            "Epoch 16/50\n",
            "2192/2192 [==============================] - 11s 5ms/step - loss: 0.8624\n",
            "Epoch 17/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8622\n",
            "Epoch 18/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8623\n",
            "Epoch 19/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8624\n",
            "Epoch 20/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8623\n",
            "Epoch 21/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8623\n",
            "Epoch 22/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8621\n",
            "Epoch 23/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8623\n",
            "Epoch 24/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8622\n",
            "Epoch 25/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8623\n",
            "Epoch 26/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8621\n",
            "Epoch 27/50\n",
            "2192/2192 [==============================] - 10s 4ms/step - loss: 0.8622\n",
            "Epoch 28/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8623\n",
            "Epoch 29/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8620\n",
            "Epoch 30/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8622\n",
            "Epoch 31/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8621\n",
            "Epoch 32/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8621\n",
            "Epoch 33/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8619\n",
            "Epoch 34/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8619\n",
            "Epoch 35/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8621\n",
            "Epoch 36/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8621\n",
            "Epoch 37/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8621\n",
            "Epoch 38/50\n",
            "2192/2192 [==============================] - 10s 4ms/step - loss: 0.8621\n",
            "Epoch 39/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8619\n",
            "Epoch 40/50\n",
            "2192/2192 [==============================] - 10s 4ms/step - loss: 0.8618\n",
            "Epoch 41/50\n",
            "2192/2192 [==============================] - 10s 4ms/step - loss: 0.8621\n",
            "Epoch 42/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8622\n",
            "Epoch 43/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8621\n",
            "Epoch 44/50\n",
            "2192/2192 [==============================] - 10s 4ms/step - loss: 0.8621\n",
            "Epoch 45/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8619\n",
            "Epoch 46/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8620\n",
            "Epoch 47/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8619\n",
            "Epoch 48/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8621\n",
            "Epoch 49/50\n",
            "2192/2192 [==============================] - 9s 4ms/step - loss: 0.8619\n",
            "Epoch 50/50\n",
            "2192/2192 [==============================] - 10s 5ms/step - loss: 0.8617\n",
            "274/274 [==============================] - 1s 2ms/step - loss: 0.8921\n",
            "274/274 [==============================] - 2s 3ms/step\n",
            "Test Loss: 0.8921324014663696\n",
            "Accuracy for Target 1: 6.63%\n",
            "Accuracy for Target 2: 8.57%\n",
            "Accuracy for Target 3: 4.72%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Total Power Generated'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Total Power Generated'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-7f66fcb8e9f9>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Calculate the total power generated (p)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mtotal_power_generated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total Power Generated'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Define the percentages for each node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Total Power Generated'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_power = power_node1 + power_node2 + power_node3\n",
        "print(\"The Total power is \",total_power)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVbHkZytJcmv",
        "outputId": "49eb1465-0971-4581-c46d-658d6a62a12b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Total power is  Pressure | (atm)                     43002.939220\n",
            "Wind speed | (m/s)                  261141.078000\n",
            "Air temperature | (°C)              674139.568000\n",
            "Power generated by system | (MW)    650072.351966\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read data from the provided DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'date': ['01-01-2019 01:00', '01-01-2019 02:00', '01-01-2019 03:00', '01-01-2019 04:00', '01-01-2019 05:00'],\n",
        "    'p1': [0.859578106, 0.862414076, 0.766688657, 0.976744083, 0.455449947],\n",
        "    'p2': [0.887444921, 0.562139051, 0.839444015, 0.929380523, 0.656946658],\n",
        "    'p3': [0.958033988, 0.781759911, 0.109853245, 0.362717774, 0.820923486],\n",
        "    'c1': [-0.782603631, -1.940058427, -1.207455592, -1.027473304, -1.125530955],\n",
        "    'c2': [-1.25739483, -1.872741686, -1.277210147, -1.938944153, -1.845974854],\n",
        "    'c3': [-1.723086311, -1.255011992, -0.920492441, -0.997373606, -0.554305008]\n",
        "})\n",
        "\n",
        "# Convert the 'date' column to datetime format\n",
        "data['date'] = pd.to_datetime(data['date'], format='%d-%m-%Y %H:%M')\n",
        "\n",
        "# Sort the DataFrame by date\n",
        "data.sort_values(by='date', inplace=True)\n",
        "\n",
        "# Prepare the data for modeling\n",
        "X = data[['p1', 'p2', 'p3']]  # Features: energy produced data\n",
        "y = data[['c1', 'c2', 'c3']]  # Targets: consumption data\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y_scaled = scaler.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the input data for LSTM\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "\n",
        "# Build the LSTM model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    tf.keras.layers.Dense(3)  # Output layer for three consumption nodes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Inverse transform the predictions to get actual values\n",
        "predictions_actual = scaler.inverse_transform(predictions)\n",
        "\n",
        "# Print the predictions\n",
        "print(\"Predictions:\")\n",
        "print(predictions_actual)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMT6pxQUBmKj",
        "outputId": "2ae3a8fb-df9f-48c2-e379-1a45eae62deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.8750\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8667\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8586\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8505\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8424\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8344\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8265\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8187\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8109\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8031\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7954\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7877\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7801\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7725\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7649\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7573\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7498\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7423\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7348\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7273\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7199\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7124\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7050\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6975\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6901\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6827\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6753\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6679\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6605\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6531\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6457\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6384\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6310\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6237\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6164\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6091\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6019\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5946\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5874\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5803\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5732\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5661\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5591\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5521\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5452\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5383\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5316\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5249\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5183\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5117\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 1.4802\n",
            "Test Loss: 1.4801994562149048\n",
            "1/1 [==============================] - 1s 600ms/step\n",
            "Predictions:\n",
            "[[-1.2043694 -1.6587538 -1.0200306]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read data from the Excel file\n",
        "data = pd.read_excel(\"/content/wind_power_gen_3months_validation_data.xlsx\")\n",
        "\n",
        "# Drop the DateTime column if not needed\n",
        "data = data.drop(columns=['DateTime'])\n",
        "\n",
        "# Convert DataFrame to numpy array\n",
        "data_array = data.values\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data_array[:, :-3]  # Features: energy produced data\n",
        "y = data_array[:, -3:]  # Targets: grid stability, unit consumption, and price per unit\n",
        "\n",
        "# Apply scaling to the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(1, input_shape=(X_train.shape[0], X_train.shape[1])),\n",
        "    tf.keras.layers.Dense(3)  # Output layer for three targets\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Print the test loss\n",
        "print(\"Test Loss:\", test_loss)\n",
        "\n",
        "# Calculate R-squared for each target\n",
        "for i in range(3):\n",
        "    train_r2 = r2_score(y_train[:, i], model.predict(X_train)[:, i])\n",
        "    test_r2 = r2_score(y_test[:, i], predictions[:, i])\n",
        "    print(f\"Target {i+1} Train R-squared:\", train_r2)\n",
        "    print(f\"Target {i+1} Test R-squared:\", test_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aFY8jguJebW",
        "outputId": "c24dc16a-a298-4e3d-9472-8175feb46dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "110/110 [==============================] - 3s 3ms/step - loss: 288.2752\n",
            "Epoch 2/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 285.8765\n",
            "Epoch 3/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 283.1950\n",
            "Epoch 4/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 280.2528\n",
            "Epoch 5/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 277.0753\n",
            "Epoch 6/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 273.7427\n",
            "Epoch 7/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 270.2836\n",
            "Epoch 8/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 266.7126\n",
            "Epoch 9/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 263.0316\n",
            "Epoch 10/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 259.2480\n",
            "Epoch 11/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 255.4508\n",
            "Epoch 12/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 251.7657\n",
            "Epoch 13/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 248.2368\n",
            "Epoch 14/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 244.8649\n",
            "Epoch 15/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 241.6473\n",
            "Epoch 16/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 238.5907\n",
            "Epoch 17/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 235.6479\n",
            "Epoch 18/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 232.8233\n",
            "Epoch 19/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 230.0845\n",
            "Epoch 20/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 227.4779\n",
            "Epoch 21/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 224.9312\n",
            "Epoch 22/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 222.4780\n",
            "Epoch 23/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 220.1066\n",
            "Epoch 24/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 217.8025\n",
            "Epoch 25/50\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 215.5667\n",
            "Epoch 26/50\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 213.3701\n",
            "Epoch 27/50\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 211.2578\n",
            "Epoch 28/50\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 209.1869\n",
            "Epoch 29/50\n",
            "110/110 [==============================] - 2s 16ms/step - loss: 207.1760\n",
            "Epoch 30/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 205.2284\n",
            "Epoch 31/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 203.2988\n",
            "Epoch 32/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 201.4308\n",
            "Epoch 33/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 199.6052\n",
            "Epoch 34/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 197.8354\n",
            "Epoch 35/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 196.0898\n",
            "Epoch 36/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 194.3851\n",
            "Epoch 37/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 192.7181\n",
            "Epoch 38/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 191.0927\n",
            "Epoch 39/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 189.5059\n",
            "Epoch 40/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 187.9428\n",
            "Epoch 41/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 186.4052\n",
            "Epoch 42/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 184.9182\n",
            "Epoch 43/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 183.4390\n",
            "Epoch 44/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 182.0006\n",
            "Epoch 45/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 180.5876\n",
            "Epoch 46/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 179.2156\n",
            "Epoch 47/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 177.8678\n",
            "Epoch 48/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 176.5356\n",
            "Epoch 49/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 175.2262\n",
            "Epoch 50/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 173.9397\n",
            "14/14 [==============================] - 1s 2ms/step - loss: 160.5195\n",
            "14/14 [==============================] - 0s 2ms/step\n",
            "Test Loss: 160.5194854736328\n",
            "55/55 [==============================] - 0s 2ms/step\n",
            "Target 1 Train R-squared: -0.03013759003375127\n",
            "Target 1 Test R-squared: -0.03048715820480008\n",
            "55/55 [==============================] - 0s 2ms/step\n",
            "Target 2 Train R-squared: -0.0030743240231660973\n",
            "Target 2 Test R-squared: -8.53080841956011e-05\n",
            "55/55 [==============================] - 0s 2ms/step\n",
            "Target 3 Train R-squared: -0.3516587028946514\n",
            "Target 3 Test R-squared: -0.302940567263968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read data from the Excel file\n",
        "data = pd.read_excel(\"/content/wind_power_gen_3months_validation_data.xlsx\")\n",
        "\n",
        "# Drop the DateTime column if not needed\n",
        "data = data.drop(columns=['DateTime'])\n",
        "\n",
        "# Convert DataFrame to numpy array\n",
        "data_array = data.values\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data_array[:, :-3]  # Features: energy produced data\n",
        "y = data_array[:, -3:]  # Targets: grid stability, unit consumption, and price per unit\n",
        "\n",
        "# Apply scaling to the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(120, input_shape=(X_train.shape[0],X_train.shape[1])),\n",
        "    tf.keras.layers.Dense(3)  # Output layer for three targets\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Print the test loss\n",
        "print(\"Test Loss:\", test_loss)\n",
        "\n",
        "# Calculate R-squared for each target\n",
        "for i in range(3):\n",
        "    train_r2 = r2_score(y_train[:, i], model.predict(X_train)[:, i])\n",
        "    test_r2 = r2_score(y_test[:, i], predictions[:, i])\n",
        "    print(f\"Target {i+1} Train R-squared:\", train_r2)\n",
        "    print(f\"Target {i+1} Test R-squared:\", test_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM0XrodlL8X-",
        "outputId": "74a08d0e-8297-4d80-8a4b-834e8e85d9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "110/110 [==============================] - 3s 4ms/step - loss: 282.7216\n",
            "Epoch 2/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 246.6161\n",
            "Epoch 3/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 189.3539\n",
            "Epoch 4/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 150.2226\n",
            "Epoch 5/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 134.2578\n",
            "Epoch 6/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 130.2788\n",
            "Epoch 7/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 129.7414\n",
            "Epoch 8/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 129.5761\n",
            "Epoch 9/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 129.5900\n",
            "Epoch 10/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 129.5425\n",
            "Epoch 11/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 129.5123\n",
            "Epoch 12/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 129.4640\n",
            "Epoch 13/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 129.4581\n",
            "Epoch 14/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 129.3820\n",
            "Epoch 15/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 129.4402\n",
            "Epoch 16/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 129.3613\n",
            "Epoch 17/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 129.3360\n",
            "Epoch 18/50\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 129.2462\n",
            "Epoch 19/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 129.2974\n",
            "Epoch 20/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 129.2391\n",
            "Epoch 21/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 129.2444\n",
            "Epoch 22/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 129.2072\n",
            "Epoch 23/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 129.2012\n",
            "Epoch 24/50\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 129.1753\n",
            "Epoch 25/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 129.0524\n",
            "Epoch 26/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 129.0995\n",
            "Epoch 27/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 129.1069\n",
            "Epoch 28/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 129.0477\n",
            "Epoch 29/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.9479\n",
            "Epoch 30/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.9072\n",
            "Epoch 31/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.8770\n",
            "Epoch 32/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.8915\n",
            "Epoch 33/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.8569\n",
            "Epoch 34/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.8282\n",
            "Epoch 35/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.8534\n",
            "Epoch 36/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.8000\n",
            "Epoch 37/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.7847\n",
            "Epoch 38/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.7580\n",
            "Epoch 39/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.6952\n",
            "Epoch 40/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.6691\n",
            "Epoch 41/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.6841\n",
            "Epoch 42/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.6260\n",
            "Epoch 43/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.6226\n",
            "Epoch 44/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.6621\n",
            "Epoch 45/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.6550\n",
            "Epoch 46/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.6685\n",
            "Epoch 47/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 128.6255\n",
            "Epoch 48/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 128.5567\n",
            "Epoch 49/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 128.6223\n",
            "Epoch 50/50\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 128.5853\n",
            "14/14 [==============================] - 1s 3ms/step - loss: 123.6404\n",
            "14/14 [==============================] - 0s 3ms/step\n",
            "Test Loss: 123.640380859375\n",
            "55/55 [==============================] - 0s 2ms/step\n",
            "Target 1 Train R-squared: -0.22587868696690783\n",
            "Target 1 Test R-squared: -0.19806103541740705\n",
            "55/55 [==============================] - 0s 2ms/step\n",
            "Target 2 Train R-squared: 0.0012383317780946257\n",
            "Target 2 Test R-squared: 0.0020046832959367267\n",
            "55/55 [==============================] - 0s 2ms/step\n",
            "Target 3 Train R-squared: 0.004304364585513865\n",
            "Target 3 Test R-squared: 0.002066163394497833\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "14KvmHrjxVQ_8NTkuz16SHEeI9Ri_968X",
      "authorship_tag": "ABX9TyMyfN3QM/SKclPqhLex4QIp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}